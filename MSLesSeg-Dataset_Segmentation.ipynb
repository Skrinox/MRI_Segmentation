{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "from ipywidgets import interact, IntSlider, ToggleButtons, fixed\n",
    "import nibabel as nib\n",
    "from other import pad_slice_to_target_shape\n",
    "from tqdm.auto import tqdm\n",
    "import h5py\n",
    "from MRI_dataset import MRIdataset_all_dims_hdf5\n",
    "from other import *\n",
    "from torch.utils.data import DataLoader\n",
    "from Unet import Unet\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torch.amp import autocast, GradScaler\n",
    "import time\n",
    "from ConbinedLoss import CombinedLoss\n",
    "from metrics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train dataset visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2124053f89d74e238e3d4050b9277dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='patient_num', options=(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.get_selected_folder_files(patient_num, folder_paths='MSLesSeg-Dataset/train/P{}')>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_paths = \"MSLesSeg-Dataset/train/P{}\"\n",
    "\n",
    "def get_selected_folder_files(patient_num, folder_paths=\"MSLesSeg-Dataset/train/P{}\"):\n",
    "    \n",
    "    MRI_folders =[folder_paths.format(patient_num) + \"/\" + folder for folder in os.listdir(folder_paths.format(patient_num))] \n",
    "\n",
    "    def get_selected_files(MRI_folder):\n",
    "\n",
    "        MRI_files = [MRI_folder + \"/\" + file for file in os.listdir(MRI_folder) if file.endswith(\".nii.gz\")]\n",
    "\n",
    "        def plot_files():\n",
    "        \n",
    "            img_tensor = [torch.tensor(load_nii(file), dtype=torch.float32) for file in MRI_files]\n",
    "            len_files = len(img_tensor)\n",
    "\n",
    "            def explore_slices(layer_sagittal, layer_coronal, layer_axial, len_files):\n",
    "\n",
    "                fig, ax = plt.subplots(3, len_files, figsize=(10, 5)) \n",
    "                for i in range(len_files):\n",
    "                    ax[0][i].grid(False)\n",
    "                    ax[0][i].imshow(img_tensor[i][layer_sagittal, :, :].T, cmap=\"gray\", origin=\"lower\")\n",
    "                    ax[0][i].set_title(MRI_files[i].split(\"/\")[-1])\n",
    "\n",
    "                    ax[1][i].grid(False)\n",
    "                    ax[1][i].imshow(img_tensor[i][:, layer_coronal, :].T, cmap=\"gray\", origin=\"lower\")\n",
    "                    ax[0][i].set_title(MRI_files[i].split(\"/\")[-1])\n",
    "\n",
    "                    ax[2][i].grid(False)\n",
    "                    ax[2][i].imshow(img_tensor[i][:, :, layer_axial].T, cmap=\"gray\", origin=\"lower\")\n",
    "                    ax[0][i].set_title(MRI_files[i].split(\"/\")[-1])\n",
    "\n",
    "            interact(explore_slices, layer_axial=(0, img_tensor[0].shape[0] - 1), layer_sagittal=(0, img_tensor[0].shape[1] - 1), layer_coronal=(0, img_tensor[0].shape[2] - 1), len_files=fixed(len_files))\n",
    "\n",
    "        interact(plot_files)\n",
    "    \n",
    "    interact(get_selected_files, MRI_folder=MRI_folders)\n",
    "\n",
    "interact(get_selected_folder_files, patient_num=[i for i in range(1, os.listdir(\"MSLesSeg-Dataset/train\").__len__() + 1)], folder_paths=fixed(folder_paths))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test dataset visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27786abbc8b44508937e75ccb35f2726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='patient_num', options=(54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64,…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.get_selected_folder_files(patient_num, folder_paths='MSLesSeg-Dataset/test/P{}')>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_paths = \"MSLesSeg-Dataset/test/P{}\"\n",
    "\n",
    "def get_selected_folder_files(patient_num, folder_paths=\"MSLesSeg-Dataset/test/P{}\"):\n",
    "    \n",
    "    MRI_files = os.listdir(folder_paths.format(patient_num))\n",
    "    MRI_files = [folder_paths.format(patient_num) + \"/\" + file for file in MRI_files if file.endswith(\".nii.gz\")]\n",
    "\n",
    "\n",
    "    def plot_files():\n",
    "    \n",
    "        img_tensor = [torch.tensor(load_nii(file), dtype=torch.float32) for file in MRI_files]\n",
    "        len_files = len(img_tensor)\n",
    "\n",
    "        def explore_slices(layer_sagittal, layer_coronal, layer_axial, len_files):\n",
    "\n",
    "            fig, ax = plt.subplots(3, len_files, figsize=(13, 8)) \n",
    "            for i in range(len_files):\n",
    "                ax[0][i].grid(False)\n",
    "                ax[0][i].imshow(img_tensor[i][layer_sagittal, :, :].T, cmap=\"gray\", origin=\"lower\")\n",
    "                ax[0][i].set_title(MRI_files[i].split(\"/\")[-1])\n",
    "\n",
    "                ax[1][i].grid(False)\n",
    "                ax[1][i].imshow(img_tensor[i][:, layer_coronal, :].T, cmap=\"gray\", origin=\"lower\")\n",
    "                ax[0][i].set_title(MRI_files[i].split(\"/\")[-1])\n",
    "\n",
    "                ax[2][i].grid(False)\n",
    "                ax[2][i].imshow(img_tensor[i][:, :, layer_axial].T, cmap=\"gray\", origin=\"lower\")\n",
    "                ax[0][i].set_title(MRI_files[i].split(\"/\")[-1])\n",
    "        \n",
    "        interact(explore_slices, layer_sagittal=(0, img_tensor[0].shape[0] - 1), layer_coronal=(0, img_tensor[0].shape[1] - 1), layer_axial=(0, img_tensor[0].shape[2] - 1), len_files=fixed(len_files))\n",
    "    \n",
    "    interact(plot_files)\n",
    "\n",
    "interact(get_selected_folder_files, patient_num=[i for i in range(54, 76)], folder_paths=fixed(folder_paths))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'MSLesSeg-Dataset/test/P{}\\P{}_FLAIR.nii.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_h5(output_file,start_num_patient, end_num_patient=53, data_path=\"MSLesSeg-Dataset/test/P{}/P{}_FLAIR.nii.gz\", roi_path=\"MSLesSeg-Dataset/test/P{}/P{}_MASK.nii.gz\"):\n",
    "    data_slices = []\n",
    "    roi_slices = []\n",
    "\n",
    "    for patient_id in tqdm(range(start_num_patient, end_num_patient + 1)):\n",
    "        data_path, roi_path = data_path.format(patient_id, patient_id), roi_path.format(patient_id, patient_id)\n",
    "        \n",
    "        if data_path:\n",
    "            data_volume = load_nii(data_path).astype(np.float32)\n",
    "            if os.path.exists(roi_path):\n",
    "                roi_volume = load_nii(roi_path).astype(np.float32)\n",
    "            else:\n",
    "                roi_volume = np.zeros_like(data_volume)\n",
    "\n",
    "            # Axial slices (z-axis)\n",
    "            for slice_idx in range(20, data_volume.shape[2]-20):\n",
    "                data_slices.append(pad_slice_to_target_shape(data_volume[:, :, slice_idx], target_shape=(224, 224)))\n",
    "                roi_slices.append(pad_slice_to_target_shape(roi_volume[:, :, slice_idx], target_shape=(224, 224)))\n",
    "\n",
    "            # Sagittal slices (x-axis)\n",
    "            for slice_idx in range(20, data_volume.shape[0]-20):\n",
    "                data_slices.append(pad_slice_to_target_shape(data_volume[slice_idx, :, :], target_shape=(224, 224)))\n",
    "                roi_slices.append(pad_slice_to_target_shape(roi_volume[slice_idx, :, :], target_shape=(224, 224)))\n",
    "        \n",
    "            # Coronal slices (y-axis)\n",
    "            for slice_idx in range(20, data_volume.shape[1]-20):\n",
    "                data_slices.append(pad_slice_to_target_shape(data_volume[:, slice_idx, :], target_shape=(224, 224)))\n",
    "                roi_slices.append(pad_slice_to_target_shape(roi_volume[:, slice_idx, :], target_shape=(224, 224)))\n",
    "\n",
    "    # Convert to numpy arrays for efficient shuffling\n",
    "    data_slices = np.array(data_slices)\n",
    "    roi_slices = np.array(roi_slices)\n",
    "\n",
    "    # Shuffle slices while keeping data and roi aligned\n",
    "    shuffle_indices = np.random.permutation(data_slices.shape[0])\n",
    "    data_slices = data_slices[shuffle_indices]\n",
    "    roi_slices = roi_slices[shuffle_indices]\n",
    "\n",
    "    # Save the shuffled slices to an HDF5 file\n",
    "    with h5py.File(output_file, 'w') as hf:\n",
    "        hf.create_dataset(\"data\", data=data_slices, compression=\"gzip\", compression_opts=9)\n",
    "        hf.create_dataset(\"roi\", data=roi_slices, compression=\"gzip\", compression_opts=9)\n",
    "\n",
    "    print(f\"Flattened, shuffled slices from all dimensions saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6fb9d7e300492dba111b7b2866e2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Flattened, shuffled slices from all dimensions saved to MSLesSeg-Dataset/test_data.h5\n"
     ]
    }
   ],
   "source": [
    "data_path = \"MSLesSeg-Dataset/test/P{}\\P{}_FLAIR.nii.gz\" # \"MSLesSeg-Dataset/train/P{}/P{}_FLAIR.nii.gz\"\n",
    "roi_path = \"MSLesSeg-Dataset/test/P{}\\P{}_MASK.nii.gz\" # \"MSLesSeg-Dataset/train/P{}/P{}_MASK.nii.gz\"\n",
    "\n",
    "create_h5(\"MSLesSeg-Dataset/test_data.h5\", 54, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded. Total slices: 24486\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "train_dataset = MRIdataset_all_dims_hdf5(hdf5_path='MSLesSeg-Dataset/train_data.h5', transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 224, 224])\n",
      "torch.Size([1, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset[0][0].shape)\n",
    "print(train_dataset[0][1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "EPOCHS = 20\n",
    "LRate = 1e-4\n",
    "\n",
    "depth = 3\n",
    "k_size = 3\n",
    "base_channels = 64\n",
    "inception = True\n",
    "\n",
    "model = Unet(in_channels=1, num_features=1, depth=depth, k_size=k_size, base_channels=base_channels, inception=inception).to(device)\n",
    "\n",
    "criterion = CombinedLoss() #  nn.BCEWithLogitsLoss() # DiceLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LRate, weight_decay=1e-5)# torch.optim.SGD(model.parameters(), lr=LRate, momentum=0.9)\n",
    "scheduler = ReduceLROnPlateau(optimizer,mode='min', factor=0.5, patience = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = GradScaler(\"cuda\")\n",
    "\n",
    "train_losses = []\n",
    "epoch_train_iou = []\n",
    "epoch_train_recall = []\n",
    "epoch_train_precision = []\n",
    "epoch_train_dice = []\n",
    "\n",
    "epoch_train_losses = []\n",
    "train_times = []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    avg_loss = 0.0\n",
    "    running_train_iou = 0.0\n",
    "    running_train_recall = 0.0\n",
    "    running_train_precision = 0.0\n",
    "    running_train_dice = 0.0\n",
    "    start = time.time()\n",
    "\n",
    "    # Training\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{EPOCHS}\", leave=False)\n",
    "    for i, (data_slice, roi_slice) in enumerate(progress_bar):\n",
    "        data_slice = data_slice.to(device)\n",
    "        roi_slice = roi_slice.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with autocast(\"cuda\"):\n",
    "          outputs = model(data_slice)\n",
    "          loss = criterion(outputs, roi_slice)\n",
    "\n",
    "        train_losses.append(loss.item())\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        # Update progress\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Compute metrics for this batch:\n",
    "        # Threshold predictions at 0.5 to obtain binary mask\n",
    "        preds = (outputs > 0.5).float()\n",
    "        # Squeeze channel dimension so shape becomes [batch, H, W]\n",
    "        preds_np = preds.squeeze(1).cpu().numpy()\n",
    "        truth_np = roi_slice.squeeze(1).cpu().numpy()\n",
    "\n",
    "        batch_iou = []\n",
    "        batch_recall = []\n",
    "        batch_precision = []\n",
    "        batch_dice = []\n",
    "        for pred_mask, truth_mask in zip(preds_np, truth_np):\n",
    "            # Use the iou_score function from metrics.py\n",
    "            batch_iou.append(iou_score(truth_mask, pred_mask))\n",
    "            batch_recall.append(recall_score_(truth_mask, pred_mask))\n",
    "            batch_precision.append(precision_score_(truth_mask, pred_mask))\n",
    "            batch_dice.append(dice_coef(truth_mask, pred_mask))\n",
    "        running_train_iou += np.mean(batch_iou)\n",
    "        running_train_recall += np.mean(batch_recall)\n",
    "        running_train_precision += np.mean(batch_precision)\n",
    "        running_train_dice += np.mean(batch_dice)\n",
    "\n",
    "        progress_bar.set_postfix({'Batch Loss': loss.item(), 'Batch IoU': np.mean(batch_iou), 'Batch Recall': np.mean(batch_recall), 'Batch Precision': np.mean(batch_precision), 'Batch Dice': np.mean(batch_dice)})\n",
    "\n",
    "    progress_bar.close()\n",
    "\n",
    "    # Average loss for the epoch\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    avg_train_iou = running_train_iou / len(train_loader)\n",
    "    avg_train_recall = running_train_recall / len(train_loader)\n",
    "    avg_train_precision = running_train_precision / len(train_loader)\n",
    "    avg_train_dice = running_train_dice / len(train_loader)\n",
    "    epoch_train_losses.append(avg_loss)\n",
    "    epoch_train_iou.append(avg_train_iou)\n",
    "    epoch_train_recall.append(avg_train_recall)\n",
    "    epoch_train_precision.append(avg_train_precision)\n",
    "    epoch_train_dice.append(avg_train_dice)\n",
    "    train_times.append(time.time() - start)\n",
    "\n",
    "    scheduler.step(avg_loss)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] Training Loss: {avg_loss:.4f}, Train IoU: {avg_train_iou:.4f}, Time: {train_times[-1]:.2f}s\")\n",
    "\n",
    "print(\"Training finished\")\n",
    "\n",
    "\n",
    "total = sum(train_times)\n",
    "hours, rem = divmod(total, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(f\"Total computation time: {int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}\")\n",
    "\n",
    "print(f\"Training time: {sum(train_times):.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"model_MSLesSeg_d{depth}_k{k_size}_b{base_channels}_incept{inception}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, EPOCHS + 1)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epoch, epoch_train_losses, label='Training Loss')\n",
    "plt.plot(epoch, epoch_train_iou, label='Training IoU')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, EPOCHS + 1)\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(epochs, epoch_train_iou, label='Train IoU')\n",
    "plt.plot(epochs, epoch_train_recall, label='Train Recall')\n",
    "plt.plot(epochs, epoch_train_precision, label='Train Precision')\n",
    "plt.plot(epochs, epoch_train_dice, label='Train Dice')\n",
    "plt.title('Training Metrics')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Metrics')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f5b0041b6d48db8510bea8dc580da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='patient_num', options=(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.get_selected_folder_files(patient_num, folder_paths='MSLesSeg-Dataset/train/P{}', model_path='MSLesSeg-Dataset/Unet_MSL.pth')>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder_paths = \"MSLesSeg-Dataset/train/P{}\"\n",
    "\n",
    "def get_selected_folder_files(patient_num, folder_paths=\"MSLesSeg-Dataset/train/P{}\", model_path=\"MSLesSeg-Dataset/Unet_MSL.pth\"):\n",
    "    \n",
    "    MRI_folders =[folder_paths.format(patient_num) + \"/\" + folder for folder in os.listdir(folder_paths.format(patient_num))] \n",
    "\n",
    "    def get_selected_files(MRI_folder):\n",
    "\n",
    "        MRI_files = [f\"P{patient_num}_T1_FLAIR.nii.gz\", f\"P{patient_num}_T1_MASK.nii.gz\"]\n",
    "        MRI_files = [MRI_folder + \"/\" + file for file in MRI_files]\n",
    "\n",
    "        def plot_files():\n",
    "        \n",
    "            img_tensor = [torch.tensor(load_nii(file), dtype=torch.float32) for file in MRI_files]\n",
    "            len_files = len(img_tensor)\n",
    "\n",
    "            model = torch.load(model_path)\n",
    "            model.eval()\n",
    "\n",
    "            def explore_slices(layer_sagittal, layer_coronal, layer_axial, len_files):\n",
    "\n",
    "                fig, ax = plt.subplots(3, len_files+1, figsize=(10, 5)) \n",
    "                for i in range(len_files):\n",
    "                    ax[0][i].grid(False)\n",
    "                    ax[0][i].imshow(img_tensor[i][layer_sagittal, :, :].T, cmap=\"gray\", origin=\"lower\")\n",
    "                    ax[0][i].set_title(MRI_files[i].split(\"/\")[-1])\n",
    "\n",
    "                    ax[1][i].grid(False)\n",
    "                    ax[1][i].imshow(img_tensor[i][:, layer_coronal, :].T, cmap=\"gray\", origin=\"lower\")\n",
    "                    ax[0][i].set_title(MRI_files[i].split(\"/\")[-1])\n",
    "\n",
    "                    ax[2][i].grid(False)\n",
    "                    ax[2][i].imshow(img_tensor[i][:, :, layer_axial].T, cmap=\"gray\", origin=\"lower\")\n",
    "                    ax[0][i].set_title(MRI_files[i].split(\"/\")[-1])\n",
    "\n",
    "                # Predict slice\n",
    "                with torch.no_grad():\n",
    "                    data_slice_sagittal = img_tensor[0][layer_sagittal, :, :].unsqueeze(0).unsqueeze(0).to(device)\n",
    "                    pred_slice_sagittal = model(data_slice_sagittal)\n",
    "                    pred_slice_sagittal = (pred_slice_sagittal > 0.5).float().squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "                    data_slice_coronal = img_tensor[0][:, layer_coronal, :].unsqueeze(0).unsqueeze(0).to(device)\n",
    "                    pred_slice_coronal = model(data_slice_coronal)\n",
    "                    pred_slice_coronal = (pred_slice_coronal > 0.5).float().squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "                    data_slice_axial = img_tensor[0][:, :, layer_axial].unsqueeze(0).unsqueeze(0).to(device)\n",
    "                    pred_slice_axial = model(data_slice_axial)\n",
    "                    pred_slice_axial = (pred_slice_axial > 0.5).float().squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "                # Plot predicted slices\n",
    "\n",
    "                ax[0][len_files].grid(False)    \n",
    "                ax[0][len_files].imshow(pred_slice_sagittal.T, cmap=\"gray\", origin=\"lower\")\n",
    "                ax[0][len_files].set_title(\"Predictions\")\n",
    "\n",
    "                ax[1][len_files].grid(False)\n",
    "                ax[1][len_files].imshow(pred_slice_coronal.T, cmap=\"gray\", origin=\"lower\")\n",
    "\n",
    "                ax[2][len_files].grid(False)\n",
    "                ax[2][len_files].imshow(pred_slice_axial.T, cmap=\"gray\", origin=\"lower\")\n",
    "\n",
    "            interact(explore_slices, layer_axial=(0, img_tensor[0].shape[0] - 1), layer_sagittal=(0, img_tensor[0].shape[1] - 1), layer_coronal=(0, img_tensor[0].shape[2] - 1), len_files=fixed(len_files))\n",
    "\n",
    "        interact(plot_files)\n",
    "    \n",
    "    interact(get_selected_files, MRI_folder=MRI_folders)\n",
    "\n",
    "interact(get_selected_folder_files, patient_num=[i for i in range(1, os.listdir(\"MSLesSeg-Dataset/train\").__len__() + 1)], folder_paths=fixed(folder_paths))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
